{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/loci/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    TokenClassificationPipeline,\n",
    "    AutoModelForTokenClassification,\n",
    "    Text2TextGenerationPipeline, # keybart\n",
    "    AutoModelForSeq2SeqLM, # keybart\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.pipelines import AggregationStrategy\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyphrase Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/ml6team/keyphrase-extraction-kbir-inspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kbir-inspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyphraseExtractionPipeline(TokenClassificationPipeline):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForTokenClassification.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def postprocess(self, all_outputs):\n",
    "        results = super().postprocess(\n",
    "            all_outputs=all_outputs,\n",
    "            aggregation_strategy=AggregationStrategy.SIMPLE,\n",
    "        )\n",
    "        return np.unique([result.get(\"word\").strip() for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 855/855 [00:00<00:00, 1.17MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.42G/1.42G [00:55<00:00, 25.5MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 1.16k/1.16k [00:00<00:00, 1.45MB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 4.24MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.40MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 6.63MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 772/772 [00:00<00:00, 3.15MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ml6team/keyphrase-extraction-kbir-inspec\"\n",
    "kbir_extractor = KeyphraseExtractionPipeline(model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keybart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/abs/2112.08547\n",
    "\n",
    "class KeyphraseGenerationPipeline(Text2TextGenerationPipeline):\n",
    "    def __init__(self, model, keyphrase_sep_token=\";\", *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForSeq2SeqLM.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.keyphrase_sep_token = keyphrase_sep_token\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        results = super().postprocess(\n",
    "            model_outputs=model_outputs\n",
    "        )\n",
    "        return [[keyphrase.strip() for keyphrase in result.get(\"generated_text\").split(self.keyphrase_sep_token) if keyphrase != \"\"] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.68k/1.68k [00:00<00:00, 12.0MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.63G/1.63G [01:12<00:00, 22.5MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 353/353 [00:00<00:00, 312kB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 6.31MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 3.95MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 8.41MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 727kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ml6team/keyphrase-generation-keybart-inspec\"\n",
    "keybart_generator = KeyphraseGenerationPipeline(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbir_inspec(text):\n",
    "    return kbir_extractor(text)\n",
    "\n",
    "def keybart_inspec(text):\n",
    "    return keybart_generator(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kbir duration: 5.394212007522583\n",
      "keybart duration: 2.6310577392578125\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "This is a no holds-barred thrilling drama mixed with killing, mayhem and manipulation among working professionals.\n",
    "This film sheds light on a man's downfall from the pinnacles of success into the depths of his damaged character.\n",
    "His insecurities lead him into a series of troubled romantic relationships and eventually a web of events that include betrayal and murder.\n",
    "\"\"\".replace(\"\\n\", \" \")\n",
    "\n",
    "t = time.time()\n",
    "keyphrases_kbir = kbir_inspec(text)\n",
    "print(\"kbir duration:\", time.time() - t)\n",
    "\n",
    "t = time.time()\n",
    "keyphrases_keybart = keybart_inspec(text)\n",
    "print(\"keybart duration:\", time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kbir ['betrayal' 'romantic relationships' 'working professionals']\n",
      "keybart ['insecurities', 'troubled romantic relationships', 'betrayal', 'murder', 'professional', 'personal']\n"
     ]
    }
   ],
   "source": [
    "print(\"kbir\", keyphrases_kbir)\n",
    "print(\"keybart\", keyphrases_keybart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rate limit:    \n",
    "> 1 request per second for the following endpoints:    \n",
    "> /paper/batch   \n",
    "> /paper/search   \n",
    "> /recommendations   \n",
    "> 10 requests / second for all other calls    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 results. Showing up to 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'paperId': '3602a1acbad352baafedaf8bea10675e9027d334',\n",
       "  'url': 'https://www.semanticscholar.org/paper/3602a1acbad352baafedaf8bea10675e9027d334',\n",
       "  'title': 'Decoding the Black Box: A Comprehensive Review of Explainable Artificial Intelligence',\n",
       "  'authors': [{'authorId': '8003685', 'name': 'Ossama H. Embarak'}]},\n",
       " {'paperId': '7dfa7d32d8ffa777095e6aa56aa629bc80742dd1',\n",
       "  'url': 'https://www.semanticscholar.org/paper/7dfa7d32d8ffa777095e6aa56aa629bc80742dd1',\n",
       "  'title': 'Artificial Intelligence in Medicine: Revolutionizing Healthcare for Improved Patient Outcomes',\n",
       "  'authors': [{'authorId': '38680767', 'name': 'Varshil Mehta'}]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_papers(papers):\n",
    "    for idx, paper in enumerate(papers):\n",
    "        print(f\"{idx}  {paper['title']} {paper['url']}\")\n",
    "\n",
    "\n",
    "def get_papers(search_words, result_limit):\n",
    "    query_words = '+'.join(search_words)\n",
    "    url = f'http://api.semanticscholar.org/graph/v1/paper/search'\n",
    "    rsp = requests.get(url,\n",
    "                        headers={'X-API-KEY': os.getenv('S2_API_KEY')},\n",
    "                        params={'query': query_words, 'limit':result_limit, 'fields':'title,authors,url'})\n",
    "    rsp.raise_for_status()\n",
    "    results = rsp.json()\n",
    "\n",
    "    total = results[\"total\"]\n",
    "    if not total:\n",
    "        raise 'No matches found. Please try another query.'\n",
    "        sys.exit()\n",
    "        \n",
    "    print(f'Found {total} results. Showing up to {result_limit}.')\n",
    "    return results['data']\n",
    "\n",
    "result_limit = 10\n",
    "get_papers(['Amazon', 'Transparency', 'Twitter', 'accountability',\n",
    "       'artificial intelligence', 'ethical', 'explainability',\n",
    "       'healthcare', 'history', 'interpretability', 'privacy',\n",
    "       'transparency'], result_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Together now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_recommendations(text, keyphrase_f):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    keyphrases = keyphrase_f(text)\n",
    "    print(\"Keyphrases:\", keyphrases)\n",
    "    papers = get_papers(keyphrases, result_limit=10)\n",
    "    print_papers(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyphrases: ['generative models', 'sequences', 'music', 'context sequences', 'randomly resampling subsequences']\n",
      "Found 9 results. Showing up to 10.\n",
      "0  A Contextual Latent Space Model: Subsequence Modulation in Melodic Sequence https://www.semanticscholar.org/paper/36d1aeff3f1e57f2f2bf3cd4f596d7797862bc86\n",
      "1  Music Generation using Deep Generative Modelling https://www.semanticscholar.org/paper/7547fa19612fa7371093df94fbd0d2108f0578b6\n",
      "2  Predictive models for music https://www.semanticscholar.org/paper/de344703e7fc244a55715cd4c8e461c5262f3c8c\n",
      "3  RESEARCH ARTICLE Predictive Models for Music https://www.semanticscholar.org/paper/d526dd4a1e9c258185a4593175c50555af224ecb\n",
      "4  Learning to Surprise: A Composer-Audience Architecture https://www.semanticscholar.org/paper/414d6998a5e838acf3c30a183e99cf8031032a79\n",
      "5  On the use of FastMap for Audio Retrieval and Browsing https://www.semanticscholar.org/paper/c9d0942b8aa3f30a625fec1bbce25b52f12cf3b7\n",
      "6  Learning to Surprise https://www.semanticscholar.org/paper/8d2188d6f3027fc2b0ef90afdc1f76f4354a4ecd\n",
      "7  Image Analysis Applications and Computer Graphics: Third International Computer Science Conference, ICSC'95 Hong Kong, December 11 - 13, 1995 Proceedings https://www.semanticscholar.org/paper/da72f2154a9b2458269d40d10376c099d1d80e84\n",
      "8  Pattern recognition and image analysis : Third Iberian Conference, IbPRIA 2007 Girona, Spain, June 6-8, 2007 : proceedings https://www.semanticscholar.org/paper/d269b467dd98182cc1253804b72ca66387dd571d\n",
      "3.3996028900146484\n"
     ]
    }
   ],
   "source": [
    "# Paper: A Contextual Latent Space Model: Subsequence Modulation in Melodic Sequence\n",
    "abstract = \"Some generative models for sequences such as music and text allow us to edit only subsequences, given surrounding context sequences, which plays an important part in steering generation interactively. However, editing subsequences mainly involves randomly resampling subsequences from a possible generation space. We propose a contextual latent space model (CLSM) in order for users to be able to explore subsequence generation with a sense of direction in the generation space, e.g., interpolation, as well as exploring variations—semantically similar possible subsequences. A context-informed prior and decoder constitute the generative model of CLSM, and a context position-informed encoder is the inference model. In experiments, we use a monophonic symbolic music dataset, demonstrating that our contextual latent space is smoother in interpolation than baselines, and the quality of generated samples is superior to baseline models. The generation examples are available online.\"\n",
    "t = time.time()\n",
    "text_recommendations(abstract, keybart_inspec)\n",
    "print(time.time() - t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "import src.embeddings as emb\n",
    "import src.similarity as sim\n",
    "import src.clustering as clu\n",
    "import src.metrics as met\n",
    "import src.metrics_fr as fr\n",
    "import src.utils as utils\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis Evaluation\n",
    "\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, n=None):\n",
    "    assert filepath[-4:] == \".csv\", \"Must be a .csv file\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    if n:\n",
    "        data = data.head(n)\n",
    "\n",
    "    attrs = {\n",
    "        \"titles\": data[\"title\"].tolist(),\n",
    "        \"text\": data[\"text\"].tolist(),\n",
    "        \"tags\": data[\"tags\"].apply(ast.literal_eval).tolist(),\n",
    "        \"ids\": data.index.tolist()\n",
    "    }\n",
    "\n",
    "    if \"simplified_tags\" in data.columns:\n",
    "        attrs[\"simplified_tags\"] = data[\"simplified_tags\"].apply(ast.literal_eval).tolist()\n",
    "\n",
    "    return attrs\n",
    "\n",
    "def load_embeddings(dataset_name, model_names):\n",
    "    embeddings = []\n",
    "    for name in model_names:\n",
    "        embeddings.append(utils.load_from_pickle(f\"embeddings/{dataset_name}_{name}_n10000.pickle\"))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: interview_prep.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"interview_prep\"\n",
    "data = load_data(f\"data/{data_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 266.61it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 38.11it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 840.21it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 283.30it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 32.67it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 437.45it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 600.22it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 43.09it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 449.79it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 375.83it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 27.35it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 741.44it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 537.39it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 34.14it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 872.00it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 153.92it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 37.99it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 1156.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_source</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>agg_method</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric</th>\n",
       "      <th>between_all_nodes</th>\n",
       "      <th>between_shared_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>cosine</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.369821</td>\n",
       "      <td>0.413958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>cosine</td>\n",
       "      <td>median</td>\n",
       "      <td>0.349550</td>\n",
       "      <td>0.431531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>cosine</td>\n",
       "      <td>std_dev</td>\n",
       "      <td>0.139443</td>\n",
       "      <td>0.140630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>soft_cosine</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.711500</td>\n",
       "      <td>0.755448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>soft_cosine</td>\n",
       "      <td>median</td>\n",
       "      <td>0.727371</td>\n",
       "      <td>0.784485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>soft_cosine</td>\n",
       "      <td>std_dev</td>\n",
       "      <td>0.134889</td>\n",
       "      <td>0.131459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.537721</td>\n",
       "      <td>0.561980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>median</td>\n",
       "      <td>0.521811</td>\n",
       "      <td>0.566406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>std_dev</td>\n",
       "      <td>0.075639</td>\n",
       "      <td>0.077599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interview_prep</td>\n",
       "      <td>mpnet</td>\n",
       "      <td>mean</td>\n",
       "      <td>cosine</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.414266</td>\n",
       "      <td>0.451403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_source embedding_model agg_method  metric_name   metric  \\\n",
       "0  interview_prep          minilm       mean       cosine     mean   \n",
       "1  interview_prep          minilm       mean       cosine   median   \n",
       "2  interview_prep          minilm       mean       cosine  std_dev   \n",
       "3  interview_prep          minilm       mean  soft_cosine     mean   \n",
       "4  interview_prep          minilm       mean  soft_cosine   median   \n",
       "5  interview_prep          minilm       mean  soft_cosine  std_dev   \n",
       "6  interview_prep          minilm       mean    euclidean     mean   \n",
       "7  interview_prep          minilm       mean    euclidean   median   \n",
       "8  interview_prep          minilm       mean    euclidean  std_dev   \n",
       "0  interview_prep           mpnet       mean       cosine     mean   \n",
       "\n",
       "   between_all_nodes  between_shared_tags  \n",
       "0           0.369821             0.413958  \n",
       "1           0.349550             0.431531  \n",
       "2           0.139443             0.140630  \n",
       "3           0.711500             0.755448  \n",
       "4           0.727371             0.784485  \n",
       "5           0.134889             0.131459  \n",
       "6           0.537721             0.561980  \n",
       "7           0.521811             0.566406  \n",
       "8           0.075639             0.077599  \n",
       "0           0.414266             0.451403  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = fr.get_embedding_similarity_metrics_per_dataset(\"interview_prep\", data[\"tags\"],\n",
    "                                             [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "                                             [\"mean\"])\n",
    "df1.to_csv(\"analysis/metric1_interview.csv\")\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Purity, Homogeneity, and Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>agg_method</th>\n",
       "      <th>clusterer</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>completeness</th>\n",
       "      <th>tag_concentration_purity</th>\n",
       "      <th>cluster_tag_purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.133</td>\n",
       "      <td>{'haha': 0.833, 'hehe': 0.667}</td>\n",
       "      <td>{'haha': 0.357, 'hehe': 0.143}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minilm</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.223</td>\n",
       "      <td>{'haha': 0.8, 'hehe': 0.75}</td>\n",
       "      <td>{'haha': 0.571, 'hehe': 0.214}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.139</td>\n",
       "      <td>{'haha': 0.75, 'hehe': 0.667}</td>\n",
       "      <td>{'haha': 0.214, 'hehe': 0.143}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.106</td>\n",
       "      <td>{'haha': 0.727, 'hehe': 0.273}</td>\n",
       "      <td>{'haha': 0.571, 'hehe': 0.214}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nomic</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.178</td>\n",
       "      <td>{'haha': 1.0, 'hehe': 0.667}</td>\n",
       "      <td>{'haha': 0.286, 'hehe': 0.143}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nomic</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.106</td>\n",
       "      <td>{'haha': 0.727, 'hehe': 0.273}</td>\n",
       "      <td>{'haha': 0.571, 'hehe': 0.214}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.086</td>\n",
       "      <td>{'haha': 0.833, 'hehe': 0.5}</td>\n",
       "      <td>{'haha': 0.357, 'hehe': 0.071}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.305</td>\n",
       "      <td>{'haha': 0.692, 'hehe': 0.308}</td>\n",
       "      <td>{'haha': 0.643, 'hehe': 0.286}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>specter</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.247</td>\n",
       "      <td>{'haha': 0.75, 'hehe': 0.5}</td>\n",
       "      <td>{'haha': 0.214, 'hehe': 0.214}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>specter</td>\n",
       "      <td>mean</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.106</td>\n",
       "      <td>{'haha': 0.727, 'hehe': 0.273}</td>\n",
       "      <td>{'haha': 0.571, 'hehe': 0.214}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding_model agg_method clusterer  homogeneity  completeness  \\\n",
       "0          minilm       mean   kmeans5        0.285         0.133   \n",
       "1          minilm       mean   kmeans2        0.205         0.223   \n",
       "2           mpnet       mean   kmeans5        0.335         0.139   \n",
       "3           mpnet       mean   kmeans2        0.084         0.106   \n",
       "4           nomic       mean   kmeans5        0.430         0.178   \n",
       "5           nomic       mean   kmeans2        0.084         0.106   \n",
       "6            bert       mean   kmeans5        0.191         0.086   \n",
       "7            bert       mean   kmeans2        0.121         0.305   \n",
       "8         specter       mean   kmeans5        0.544         0.247   \n",
       "9         specter       mean   kmeans2        0.084         0.106   \n",
       "\n",
       "         tag_concentration_purity              cluster_tag_purity  \n",
       "0  {'haha': 0.833, 'hehe': 0.667}  {'haha': 0.357, 'hehe': 0.143}  \n",
       "1     {'haha': 0.8, 'hehe': 0.75}  {'haha': 0.571, 'hehe': 0.214}  \n",
       "2   {'haha': 0.75, 'hehe': 0.667}  {'haha': 0.214, 'hehe': 0.143}  \n",
       "3  {'haha': 0.727, 'hehe': 0.273}  {'haha': 0.571, 'hehe': 0.214}  \n",
       "4    {'haha': 1.0, 'hehe': 0.667}  {'haha': 0.286, 'hehe': 0.143}  \n",
       "5  {'haha': 0.727, 'hehe': 0.273}  {'haha': 0.571, 'hehe': 0.214}  \n",
       "6    {'haha': 0.833, 'hehe': 0.5}  {'haha': 0.357, 'hehe': 0.071}  \n",
       "7  {'haha': 0.692, 'hehe': 0.308}  {'haha': 0.643, 'hehe': 0.286}  \n",
       "8     {'haha': 0.75, 'hehe': 0.5}  {'haha': 0.214, 'hehe': 0.214}  \n",
       "9  {'haha': 0.727, 'hehe': 0.273}  {'haha': 0.571, 'hehe': 0.214}  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = fr.compare_cluster_metrics(\"interview_prep\",\n",
    "                                    [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "                                    [\"mean\"],\n",
    "                                    {\n",
    "                                        \"kmeans5\": lambda x: clu.kmeans(x),\n",
    "                                        \"kmeans2\": lambda x: clu.kmeans(x, 2)\n",
    "                                    }, data[\"ids\"], data[\"tags\"], k=2)\n",
    "df2.to_csv(\"analysis/metric2_interview.csv\")\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Assignment Evaluation: Tag Connectivity and Degree of Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.edge_constructors as edge\n",
    "import src.aggregation as agg\n",
    "import src.pipeline as pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 130.79it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 652.71it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 4080.06it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 2882.68it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 1677.72it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 2008.77it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 312.98it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"interview_prep\"\n",
    "embedding_model = \"bert\"\n",
    "agg_method = \"mean\"\n",
    "embeddings = utils.load_from_pickle(f\"embeddings/{dataset_name}_{embedding_model}_{agg_method}_n10000.pickle\")\n",
    "\n",
    "metric = \"cosine\"\n",
    "similarity_scores = sim.batch_similarity_scores(embeddings, metric)\n",
    "edge_constructor_f = lambda sim_mat, ids: edge.knn(sim_mat, ids, k=3)\n",
    "clusterer_f = lambda emb: clu.kmeans(emb, n_clusters=5)\n",
    "\n",
    "\n",
    "G = pipe.cluster_and_connect(embeddings, similarity_scores, data[\"ids\"],\n",
    "                             metric,\n",
    "                             edge_constructor_f,\n",
    "                             clusterer_f,\n",
    "                             aggregator_f=agg.mean_pooling,\n",
    "                             titles=data[\"titles\"], tags=data[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (1, 0.05), 2: (6, 0.3), 3: (8, 0.4)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.bfs_tag_connectivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8678350097093828"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.degree_of_separation(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag_connectivity': {1: (1, 0.05), 2: (6, 0.3), 3: (8, 0.4)},\n",
       " 'degree_of_separation': 1.8678350097093828}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.calculate_edge_assignment_metrics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compare_edge_assignment_metrics() got an unexpected keyword argument 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare_edge_assignment_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minterview_prep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mminilm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmpnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnomic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword2vec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkmeans5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mclu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkmeans2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mclu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mknn3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msim_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43medge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mknn5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msim_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43medge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m df\n",
      "\u001b[0;31mTypeError\u001b[0m: compare_edge_assignment_metrics() got an unexpected keyword argument 'k'"
     ]
    }
   ],
   "source": [
    "df = fr.compare_edge_assignment_metrics(\"interview_prep\",\n",
    "                                        [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"],\n",
    "                                        [\"mean\"],\n",
    "                                        {\n",
    "                                            \"kmeans5\": lambda x: clu.kmeans(x),\n",
    "                                            \"kmeans2\": lambda x: clu.kmeans(x, 2)\n",
    "                                        },\n",
    "                                        {\n",
    "                                            \"knn3\": lambda sim_mat, ids: edge.knn(sim_mat, ids, k=3),\n",
    "                                            \"knn5\": lambda sim_mat, ids: edge.knn(sim_mat, ids, k=5)\n",
    "                                        }, data[\"ids\"], data[\"tags\"], data[\"titles\"], max_depth=3)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Medium (n=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikluu/Documents/Poly/Thesis/LociNet/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "import src.embeddings as emb\n",
    "import src.similarity as sim\n",
    "import src.clustering as clu\n",
    "import src.metrics as met\n",
    "import src.metrics_fr as fr\n",
    "import src.utils as utils\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis Evaluation\n",
    "\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, n=None):\n",
    "    assert filepath[-4:] == \".csv\", \"Must be a .csv file\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    if n:\n",
    "        data = data.head(n)\n",
    "\n",
    "    attrs = {\n",
    "        \"titles\": data[\"title\"].tolist(),\n",
    "        \"text\": data[\"text\"].tolist(),\n",
    "        \"tags\": data[\"tags\"].apply(ast.literal_eval).tolist(),\n",
    "        \"ids\": data.index.tolist()\n",
    "    }\n",
    "\n",
    "    if \"simplified_tags\" in data.columns:\n",
    "        attrs[\"simplified_tags\"] = data[\"simplified_tags\"].apply(ast.literal_eval).tolist()\n",
    "\n",
    "    return attrs\n",
    "\n",
    "def load_embeddings(dataset_name, model_names):\n",
    "    embeddings = []\n",
    "    for name in model_names:\n",
    "        embeddings.append(utils.load_from_pickle(f\"embeddings/{dataset_name}_{name}_n10000.pickle\"))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: interview_prep.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"interview_prep\"\n",
    "data = load_data(f\"data/{data_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_similarity_metrics_per_dataset(dataset_name, dataset_tags, model_names):\n",
    "    dataframes = []\n",
    "\n",
    "    for model_name in model_names:\n",
    "        embeddings = utils.load_from_pickle(f\"embeddings/{dataset_name}_{model_name}_n10000.pickle\")\n",
    "        cosine_sim, soft_cosine_sim, euclidean_sim = sim.get_all_similarities(embeddings)\n",
    "        dataframes.append(fr.calculate_embedding_metrics_for_all(cosine_sim, soft_cosine_sim, euclidean_sim,\n",
    "                                        dataset_tags, model_name, dataset_name))\n",
    "    \n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 370.36it/s]\n",
      "Calculating soft_cosine similarities:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 46.53it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 211.87it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 1035.37it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 66.46it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 1406.54it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 1128.41it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 66.15it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 2101.35it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 208.11it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 68.87it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 772.01it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 488.28it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 66.09it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 66.84it/s]\n",
      "Calculating cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 134.68it/s]\n",
      "Calculating soft_cosine similarities: 100%|██████████| 1/1 [00:00<00:00, 134.53it/s]\n",
      "Calculating euclidean similarities: 100%|██████████| 1/1 [00:00<00:00, 2487.72it/s]\n"
     ]
    }
   ],
   "source": [
    "df = get_embedding_similarity_metrics_per_dataset(\"interview_prep\", data[\"tags\"],\n",
    "                                             [\"minilm\", \"mpnet\", \"nomic\", \"bert\", \"specter\", \"word2vec\"])\n",
    "df.to_csv(\"analysis/metric1_interview.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Purity, Homogeneity, and Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>clusterer</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>completeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minilm</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>0.285179</td>\n",
       "      <td>0.132731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minilm</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>0.205075</td>\n",
       "      <td>0.223409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>0.190594</td>\n",
       "      <td>0.086402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>0.120603</td>\n",
       "      <td>0.305471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding_model clusterer  homogeneity  completeness\n",
       "0          minilm   kmeans5     0.285179      0.132731\n",
       "1          minilm   kmeans2     0.205075      0.223409\n",
       "2            bert   kmeans5     0.190594      0.086402\n",
       "3            bert   kmeans2     0.120603      0.305471"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.compare_completeness_homogeneity(\"interview_prep\",\n",
    "                                    [\"minilm\", \"bert\"],\n",
    "                                    {\n",
    "                                        \"kmeans5\": lambda x: clu.kmeans(x),\n",
    "                                        \"kmeans2\": lambda x: clu.kmeans(x, 2)\n",
    "                                    }, data[\"ids\"], data[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>clusterer</th>\n",
       "      <th>tag_concentration_purity</th>\n",
       "      <th>cluster_tag_purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minilm</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>{'e': 0.0, 'i': 0.0}</td>\n",
       "      <td>{'e': 0.0, 'i': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minilm</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>{'e': 0.0, 'i': 0.0}</td>\n",
       "      <td>{'e': 0.0, 'i': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>kmeans5</td>\n",
       "      <td>{'e': 0.0, 'i': 0.0}</td>\n",
       "      <td>{'e': 0.0, 'i': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert</td>\n",
       "      <td>kmeans2</td>\n",
       "      <td>{'e': 0.0, 'i': 0.0}</td>\n",
       "      <td>{'e': 0.0, 'i': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding_model clusterer tag_concentration_purity    cluster_tag_purity\n",
       "0          minilm   kmeans5     {'e': 0.0, 'i': 0.0}  {'e': 0.0, 'i': 0.0}\n",
       "1          minilm   kmeans2     {'e': 0.0, 'i': 0.0}  {'e': 0.0, 'i': 0.0}\n",
       "2            bert   kmeans5     {'e': 0.0, 'i': 0.0}  {'e': 0.0, 'i': 0.0}\n",
       "3            bert   kmeans2     {'e': 0.0, 'i': 0.0}  {'e': 0.0, 'i': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.compare_purity_metrics(\"interview_prep\",\n",
    "                                    [\"minilm\", \"bert\"],\n",
    "                                    {\n",
    "                                        \"kmeans5\": lambda x: clu.kmeans(x),\n",
    "                                        \"kmeans2\": lambda x: clu.kmeans(x, 2)\n",
    "                                    }, data[\"ids\"], data[\"tags\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts = fr.get_tags_count(data[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = utils.load_from_pickle(\"embeddings/interview_prep_bert_n10000.pickle\")\n",
    "clusterer_f = lambda x: clu.kmeans(x, n_clusters=5)\n",
    "ids_by_cluster = fr.ids_by_clusters(embeddings, data[\"ids\"], clusterer_f)\n",
    "tags_by_cluster = fr.tags_by_clusters(ids_by_cluster, data[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [['hehe'], ['haha'], ['haha'], ['haha'], ['haha'], ['haha']],\n",
       " 1: [['hehe']],\n",
       " 2: [['hehe'], ['haha']],\n",
       " 3: [['hehe'], ['haha'], ['haha']],\n",
       " 4: [['hehe'], ['haha']]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_by_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0.8333333333333334]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0.16666666666666666, 1.0, 0.5, 0.3333333333333333, 0.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.19059410036757143,\n",
       " 0.08640246970929145,\n",
       " {'haha': 0.8333333333333334, 'hehe': 0.5},\n",
       " {'haha': 0.35714285714285715, 'hehe': 0.07142857142857142})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.calculate_homogeneity(tags_by_cluster), \\\n",
    "    fr.calculate_completeness(tags_by_cluster), \\\n",
    "    fr.calculate_tag_concentration_purity(tags_by_cluster, tag_counts, 2), \\\n",
    "    fr.calculate_cluster_tag_purity(tags_by_cluster, tag_counts, sum(tag_counts.values()), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_and_clusterers(data, embedding_models, embeddings, clusterers, k=2):\n",
    "    results = []\n",
    "    for name, e in zip(embedding_models, embeddings):\n",
    "        for clusterer_name, clusterer_f in clusterers.items():\n",
    "            clusters = clusterer_f(e)\n",
    "            cluster_tags = {i: [] for i in range(max(clusters) + 1)}\n",
    "\n",
    "            for i, cluster_id in enumerate(clusters):\n",
    "                cluster_tags[cluster_id].extend(data['tags'][i])  # Assuming data is a list of dictionaries with 'tags' field\n",
    "\n",
    "            total_tag_counts = Counter(tag for tags in cluster_tags.values() for tag in tags)\n",
    "            metrics_df = met.calculate_metrics_dataframe(cluster_tags, total_tag_counts, k)\n",
    "            metrics_df[\"Model\"] = name\n",
    "            metrics_df[\"Clusterer\"] = clusterer_name\n",
    "\n",
    "            results.append(metrics_df)\n",
    "\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m load_embeddings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium1k\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding_models)\n\u001b[1;32m      3\u001b[0m clusterers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: clu\u001b[38;5;241m.\u001b[39mkmeans(x, n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbscan\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: clu\u001b[38;5;241m.\u001b[39mdbscan(x)\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m \u001b[43mevaluate_models_and_clusterers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusterers\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m, in \u001b[0;36mevaluate_models_and_clusterers\u001b[0;34m(data, embedding_models, embeddings, clusterers, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m cluster_tags \u001b[38;5;241m=\u001b[39m {i: [] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmax\u001b[39m(clusters) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, cluster_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clusters):\n\u001b[0;32m----> 9\u001b[0m     cluster_tags[cluster_id]\u001b[38;5;241m.\u001b[39mextend(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Assuming data is a list of dictionaries with 'tags' field\u001b[39;00m\n\u001b[1;32m     11\u001b[0m total_tag_counts \u001b[38;5;241m=\u001b[39m Counter(tag \u001b[38;5;28;01mfor\u001b[39;00m tags \u001b[38;5;129;01min\u001b[39;00m cluster_tags\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags)\n\u001b[1;32m     12\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m met\u001b[38;5;241m.\u001b[39mcalculate_metrics_dataframe(cluster_tags, total_tag_counts, k)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "embedding_models = [\"nomic\", \"minilm\", \"mpnet\", \"bert\", \"specter\"]\n",
    "embeddings = load_embeddings(\"medium1k\", embedding_models)\n",
    "clusterers = {\n",
    "    \"kmeans\": lambda x: clu.kmeans(x, n_clusters=5),\n",
    "    \"dbscan\": lambda x: clu.dbscan(x)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing sentence-transformers/all-MiniLM-L6-v2 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: This is a project I ...: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Purity</th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Completeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haha</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.285179</td>\n",
       "      <td>0.132731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hehe</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.285179</td>\n",
       "      <td>0.132731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tag    Purity  Homogeneity  Completeness\n",
       "0  haha  0.555556     0.285179      0.132731\n",
       "1  hehe  0.400000     0.285179      0.132731"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"minilm\"\n",
    "embeddings = emb.process_embeddings(data[\"text\"], model_name)\n",
    "clusterer_f = lambda x: clu.kmeans(x, n_clusters=5)\n",
    "clusters = met.get_clusters_with_tags(embeddings, data[\"tags\"], clusterer_f)\n",
    "tag_counts = met.get_tags_count(data[\"tags\"])\n",
    "met.calculate_metrics_dataframe(clusters, tag_counts, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Medium (n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_embedding_similarity_metrics_per_data(\"medium1k\", data[\"tags\"],\n",
    "                                             [\"minilm\"])\n",
    "#  \"mpnet\", \"nomic\", \"bert\", \"specter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_minilm_df = met.calculate_embedding_metrics_for_all(minilm_cosine_sim, minilm_soft_cosine_sim, minilm_euclidean_sim,\n",
    "#                                         tags, \"minilm\", data_name)\n",
    "# all_mpnet_df = met.calculate_embedding_metrics_for_all(mpnet_cosine_sim, mpnet_soft_cosine_sim, mpnet_euclidean_sim,\n",
    "#                                         tags, \"mpnet\", data_name)\n",
    "# nomic_df = met.calculate_embedding_metrics_for_all(nomic_cosine_sim, nomic_soft_cosine_sim, nomic_euclidean_sim,\n",
    "#                                         tags, \"nomic\", data_name)\n",
    "# bert_df = met.calculate_embedding_metrics_for_all(bert_cosine_sim, bert_soft_cosine_sim, bert_euclidean_sim,\n",
    "#                                         tags, \"bert\", data_name)\n",
    "# specter_df = met.calculate_embedding_metrics_for_all(specter_cosine_sim, specter_soft_cosine_sim, specter_euclidean_sim,\n",
    "#                                         tags, \"specter\", data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.concat([all_minilm_df, nomic_df, all_mpnet_df, bert_df, specter_df], ignore_index=True)\n",
    "# melted_df = combined_df.melt(id_vars=['data_source', 'embedding_model', 'metric_name', 'metric'], \n",
    "#                              value_vars=['between_all_nodes', 'between_shared_tags'], \n",
    "#                              var_name='comparison_type', value_name='value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
